{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMtFG9w91Qd1S+hpehBrhpv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 0. ë“œë¼ì´ë¸Œ ì—°ê²°"],"metadata":{"id":"_hBfwrg2AaPW"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"cnEOjaRJkWoR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. ê¸°ì¡´ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ"],"metadata":{"id":"3eAs9EVBAd0N"}},{"cell_type":"code","source":["import pandas as pd\n","\n","path = \"/content/drive/MyDrive/DILAB/Qwen2-7B-Instruct/results/original_1.3/original_1_3_results.parquet\"\n","\n","VIEW_NUM = 15\n","\n","df = pd.read_parquet(path)\n","\n","for idx, row in df.iterrows():\n","  print(f\"\\nğŸ“Œ======= {idx + 1}ë²ˆ í–‰ =======ğŸ“Œ\")\n","\n","  for i, col in enumerate(df.columns, start=1):\n","    value = row[col]\n","\n","    print(f\"âœ…{i}. {col}\\n{value}\\n\")"],"metadata":{"id":"vUW08aDSHd-t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. ë°ì´í„° ë§¤í•‘"],"metadata":{"id":"0JdWUQZBAjOk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mefdBUckSOD"},"outputs":[],"source":["import pandas as pd\n","\n","path = \"/content/drive/MyDrive/DILAB/Qwen2-7B-Instruct/results/original_1.3/original_1_3_results.parquet\"\n","VIEW_NUM = 10\n","\n","df = pd.read_parquet(path)\n","\n","# 1. ì¶œë ¥í•  ì»¬ëŸ¼ ì´ë¦„ë“¤ë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜\n","columns_to_print = [\n","    'original_model_output',\n","    'trained_model_output',\n","    'original_bhc',\n","    'original_di'\n","]\n","\n","# 2. ì›ë˜ ì»¬ëŸ¼ ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n","col_indices = {col: df.columns.get_loc(col) + 1 for col in columns_to_print}\n","\n","# 3. VIEW_NUM ë§Œí¼ë§Œ ìƒìœ„ Nê°œ í–‰ì„ ê°€ì ¸ì˜´\n","for idx, row in df.head(VIEW_NUM).iterrows():\n","    print(f\"\\nğŸ“Œ======= {idx + 1}ë²ˆ í–‰ =======ğŸ“Œ\")\n","\n","    # 4. ì •ì˜í•œ ë¦¬ìŠ¤íŠ¸(columns_to_print)ì— ìˆëŠ” ì»¬ëŸ¼ë“¤ë§Œ ë°˜ë³µ\n","    for col_name in columns_to_print:\n","        value = row[col_name]\n","        original_index = col_indices[col_name]  # ì €ì¥í•´ë‘” ì›ë˜ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°\n","\n","        print(f\"âœ…{original_index}. {col_name}\\n{value}\\n\")"]},{"cell_type":"markdown","source":["# 2.1 ë°ì´í„° ë¶„í•  í™•ì¸"],"metadata":{"id":"txC_vY6iAuQT"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","\n","path = \"/content/drive/MyDrive/DILAB/Qwen2-7B-Instruct/results/original_1.3/original_1_3_results.parquet\"\n","VIEW_NUM = 5 # í™•ì¸í•  í–‰ ê°œìˆ˜ ì¡°ì ˆ\n","\n","df = pd.read_parquet(path)\n","\n","# í…ìŠ¤íŠ¸ ë¶„ë¦¬ í•¨ìˆ˜\n","def split_bhc_di(text):\n","    if not isinstance(text, str):\n","        return \"\", \"\"\n","    bhc_pattern = r\"Brief Hospital Course\\s*\"\n","    di_pattern = r\"Discharge Instructions\\s*\"\n","    bhc_match = re.search(bhc_pattern, text, re.IGNORECASE)\n","    di_match = re.search(di_pattern, text, re.IGNORECASE)\n","    bhc_text = \"\"\n","    di_text = \"\"\n","\n","    if bhc_match and di_match:\n","        bhc_start = bhc_match.end()\n","        bhc_end = di_match.start()\n","        # BHC í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë§¨ ì• ì½œë¡  ë° ê´€ë ¨ ê³µë°± ì œê±°\n","        bhc_text = text[bhc_start:bhc_end].strip().lstrip(':').strip()\n","        di_start = di_match.end()\n","        # DI í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë§¨ ì• ì½œë¡  ë° ê´€ë ¨ ê³µë°± ì œê±°\n","        di_text = text[di_start:].strip().lstrip(':').strip()\n","    elif bhc_match:\n","        bhc_start = bhc_match.end()\n","        # BHC í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë§¨ ì• ì½œë¡  ë° ê´€ë ¨ ê³µë°± ì œê±°\n","        bhc_text = text[bhc_start:].strip().lstrip(':').strip()\n","    elif di_match:\n","        di_start = di_match.end()\n","        # DI í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë§¨ ì• ì½œë¡  ë° ê´€ë ¨ ê³µë°± ì œê±°\n","        di_text = text[di_start:].strip().lstrip(':').strip()\n","    return bhc_text, di_text\n","\n","# ìƒìœ„ VIEW_NUM ê°œ í–‰ì— ëŒ€í•´ ë¶„í•  ê²°ê³¼ ì¶œë ¥\n","for idx, row in df.head(VIEW_NUM).iterrows():\n","    print(f\"\\n\\n\\nğŸ“Œ======= {idx + 1}ë²ˆ í–‰ ë¶„í•  ê²°ê³¼ í™•ì¸ =======ğŸ“Œ\")\n","\n","    # ì›ë³¸ ëª¨ë¸ ì¶œë ¥ ê°€ì ¸ì˜¤ê¸° ë° ë¶„ë¦¬\n","    om_output = row['original_model_output']\n","    om_bhc, om_di = split_bhc_di(om_output)\n","\n","    # íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶œë ¥ ê°€ì ¸ì˜¤ê¸° ë° ë¶„ë¦¬\n","    tm_output = row['trained_model_output']\n","    tm_bhc, tm_di = split_bhc_di(tm_output)\n","\n","    # ì •ë‹µ ê°€ì ¸ì˜¤ê¸°\n","    gt_bhc = str(row['original_bhc']) if pd.notna(row['original_bhc']) else \"\"\n","    gt_di = str(row['original_di']) if pd.notna(row['original_di']) else \"\"\n","\n","    print(\"\\n--- [ì›ë³¸ ëª¨ë¸ BHC] ---\")\n","    print(om_bhc)\n","\n","    print(\"\\n\\n--- [ì›ë³¸ ëª¨ë¸ DI] ---\")\n","    print(om_di)\n","\n","    print(\"\\n\\n--- [íŒŒì¸íŠœë‹ ëª¨ë¸ BHC] ---\")\n","    print(tm_bhc)\n","\n","    print(\"\\n\\n--- [íŒŒì¸íŠœë‹ ëª¨ë¸ DI] ---\")\n","    print(tm_di)\n","\n","    print(\"\\n--- [ì •ë‹µ BHC] ---\")\n","    print(gt_bhc)\n","\n","    print(\"\\n--- [ì •ë‹µ DI] ---\")\n","    print(gt_di)\n","    print(\"=\" * 40) # í–‰ êµ¬ë¶„"],"metadata":{"id":"_A2A8s1mJtz6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. í‰ê°€ (BERTScore)"],"metadata":{"id":"l5W0QTMAA2MO"}},{"cell_type":"code","source":["# í‰ê°€ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´\n","!pip uninstall transformers bert-score -y\n","!pip install transformers bert-score"],"metadata":{"id":"0638_5emJdtO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from bert_score import score\n","import re\n","import warnings\n","import torch\n","import numpy as np # NaN ê°’ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ numpy ì„í¬íŠ¸\n","\n","# bert_score ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ\n","warnings.filterwarnings(\"ignore\", message=\"Some weights of RobertaModel were not initialized from the model checkpoint\")\n","\n","# --- ì„¤ì • ---\n","path = \"/content/drive/MyDrive/DILAB/Qwen2-7B-Instruct/results/original_1.3/original_1_3_results.parquet\"\n","VIEW_NUM = None # Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ í–‰ ì²˜ë¦¬, ìˆ«ìë¡œ ì§€ì •í•˜ë©´ ìƒìœ„ Nê°œ í–‰ë§Œ ì²˜ë¦¬\n","MODEL_TYPE = \"roberta-large\" # BERTScore ê³„ì‚°ì— ì‚¬ìš©í•  ëª¨ë¸\n","# --- ì„¤ì • ë ---\n","\n","# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° device ì„¤ì • (ë¬¸ìì—´ë¡œ ë³€ê²½)\n","if torch.cuda.is_available():\n","    device = \"cuda:0\" # GPU ì‚¬ìš© ì‹œ ë¬¸ìì—´ \"cuda:0\"\n","    print(\"Using device: GPU\")\n","else:\n","    device = \"cpu\"    # CPU ì‚¬ìš© ì‹œ ë¬¸ìì—´ \"cpu\"\n","    print(\"Using device: CPU\")\n","\n","\n","df = pd.read_parquet(path)\n","\n","# í…ìŠ¤íŠ¸ ë¶„ë¦¬ í•¨ìˆ˜ (ë§¨ ì• ì½œë¡  ì œê±° í¬í•¨, ê²€ì¦ ì™„ë£Œ)\n","def split_bhc_di(text):\n","    if not isinstance(text, str):\n","        return \"\", \"\"\n","    bhc_pattern = r\"Brief Hospital Course\\s*\"\n","    di_pattern = r\"Discharge Instructions\\s*\"\n","    bhc_match = re.search(bhc_pattern, text, re.IGNORECASE)\n","    di_match = re.search(di_pattern, text, re.IGNORECASE)\n","    bhc_text = \"\"\n","    di_text = \"\"\n","    if bhc_match and di_match:\n","        bhc_start = bhc_match.end()\n","        bhc_end = di_match.start()\n","        bhc_text = text[bhc_start:bhc_end].strip().lstrip(':').strip()\n","        di_start = di_match.end()\n","        di_text = text[di_start:].strip().lstrip(':').strip()\n","    elif bhc_match:\n","        bhc_start = bhc_match.end()\n","        bhc_text = text[bhc_start:].strip().lstrip(':').strip()\n","    elif di_match:\n","        di_start = di_match.end()\n","        di_text = text[di_start:].strip().lstrip(':').strip()\n","    return bhc_text, di_text\n","\n","# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n","bert_scores = []\n","\n","# ì²˜ë¦¬í•  í–‰ ê²°ì •\n","if VIEW_NUM is None:\n","    rows_to_process = df.iterrows()\n","    total_rows = len(df)\n","else:\n","    rows_to_process = df.head(VIEW_NUM).iterrows()\n","    total_rows = VIEW_NUM\n","\n","print(f\"ì´ {total_rows}ê°œ í–‰ì— ëŒ€í•œ BERTScore ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤ (ëª¨ë¸: {MODEL_TYPE}, ì¥ì¹˜: {device})...\")\n","\n","# í–‰ ë°˜ë³µ, í…ìŠ¤íŠ¸ ë¶„ë¦¬, BERTScore ê³„ì‚°\n","for idx, row in rows_to_process:\n","    if (idx + 1) % 50 == 0: # 50í–‰ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥\n","        print(f\"í–‰ {idx + 1}/{total_rows} ì²˜ë¦¬ ì¤‘...\")\n","\n","    # ëª¨ë¸ ì¶œë ¥ê°’ ê°€ì ¸ì˜¤ê¸°\n","    om_output = row['original_model_output']\n","    tm_output = row['trained_model_output']\n","\n","    # ì •ë‹µ(Ground Truth) ê°€ì ¸ì˜¤ê¸° (NaN ê°’ ì²˜ë¦¬)\n","    gt_bhc = str(row['original_bhc']) if pd.notna(row['original_bhc']) else \"\"\n","    gt_di = str(row['original_di']) if pd.notna(row['original_di']) else \"\"\n","\n","    # ëª¨ë¸ ì¶œë ¥ê°’ ë¶„ë¦¬\n","    om_bhc, om_di = split_bhc_di(om_output)\n","    tm_bhc, tm_di = split_bhc_di(tm_output)\n","\n","    # --- BERTScore ê³„ì‚° (6ê°€ì§€ ë¹„êµ) ---\n","    # ì ìˆ˜ ë³€ìˆ˜ë¥¼ NaNìœ¼ë¡œ ì´ˆê¸°í™”\n","    f1_om_gt_bhc, f1_tm_gt_bhc, f1_om_gt_di, f1_tm_gt_di = np.nan, np.nan, np.nan, np.nan\n","    f1_om_tm_bhc, f1_om_tm_di = np.nan, np.nan\n","\n","    # ê³„ì‚° í•¨ìˆ˜ ì •ì˜ (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)\n","    def calculate_f1(candidates, references):\n","        # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ë¹ˆ ë¬¸ìì—´ ì²´í¬ ì œê±° (í˜¸ì¶œ ì „ì— ì²´í¬)\n","        try:\n","            _, _, F1 = score(candidates, references, model_type=MODEL_TYPE, lang='en', verbose=False, device=device)\n","            return F1[0].item() if F1.numel() > 0 else 0.0 # 0.0 ë°˜í™˜ ìœ ì§€ (ì˜¤ë¥˜ ì‹œ)\n","        except Exception as e:\n","            print(f\" - í–‰ {idx + 1} ê³„ì‚° ì˜¤ë¥˜: {e}\")\n","            return np.nan # ì˜¤ë¥˜ ë°œìƒ ì‹œ NaN ë°˜í™˜\n","\n","    # ì ìˆ˜ ê³„ì‚°\n","    if om_bhc and gt_bhc:\n","        f1_om_gt_bhc = calculate_f1([om_bhc], [gt_bhc])\n","    if tm_bhc and gt_bhc:\n","        f1_tm_gt_bhc = calculate_f1([tm_bhc], [gt_bhc])\n","    if om_di and gt_di:\n","        f1_om_gt_di  = calculate_f1([om_di], [gt_di])\n","    if tm_di and gt_di:\n","        f1_tm_gt_di  = calculate_f1([tm_di], [gt_di])\n","    if om_bhc and tm_bhc: # OM vs TM ë¹„êµë„ ì–‘ìª½ ë‹¤ ìˆì–´ì•¼ ê³„ì‚°\n","        f1_om_tm_bhc = calculate_f1([om_bhc], [tm_bhc])\n","    if om_di and tm_di: # OM vs TM ë¹„êµë„ ì–‘ìª½ ë‹¤ ìˆì–´ì•¼ ê³„ì‚°\n","        f1_om_tm_di  = calculate_f1([om_di], [tm_di])\n","\n","\n","    # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n","    bert_scores.append({\n","        'row_index': idx + 1,\n","        'F1_OM_vs_GT_BHC': f1_om_gt_bhc,\n","        'F1_TM_vs_GT_BHC': f1_tm_gt_bhc,\n","        'F1_OM_vs_GT_DI': f1_om_gt_di,\n","        'F1_TM_vs_GT_DI': f1_tm_gt_di,\n","        'F1_OM_vs_TM_BHC': f1_om_tm_bhc,\n","        'F1_OM_vs_TM_DI': f1_om_tm_di,\n","    })\n","\n","print(f\"ì´ {total_rows}ê°œ í–‰ì— ëŒ€í•œ BERTScore ê³„ì‚° ì™„ë£Œ.\")\n","\n","# ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n","results_df = pd.DataFrame(bert_scores)\n","\n","# ê²°ê³¼ ì¶œë ¥ (ìƒìœ„ 5ê°œ í–‰)\n","print(\"\\n===== BERTScore F1 ê²°ê³¼ (ìƒìœ„ 5ê°œ í–‰) =====\")\n","print(results_df.head()) # NaN ê°’ì´ í¬í•¨ëœ ì±„ë¡œ ì¶œë ¥ë  ìˆ˜ ìˆìŒ\n","\n","# í‰ê·  ì ìˆ˜ ì¶œë ¥\n","print(\"\\n===== í‰ê·  BERTScore F1 (NaN ì œì™¸) =====\")\n","avg_scores = results_df.mean(numeric_only=True) # skipna=Trueê°€ ê¸°ë³¸ê°’\n","print(f\"ì›ë³¸ ëª¨ë¸ BHC vs ì •ë‹µ BHC: {avg_scores.get('F1_OM_vs_GT_BHC', 0.0):.4f}\")\n","print(f\"íŒŒì¸íŠœë‹ ëª¨ë¸ BHC vs ì •ë‹µ BHC: {avg_scores.get('F1_TM_vs_GT_BHC', 0.0):.4f}\")\n","print(f\"ì›ë³¸ ëª¨ë¸ DI vs ì •ë‹µ DI: {avg_scores.get('F1_OM_vs_GT_DI', 0.0):.4f}\")\n","print(f\"íŒŒì¸íŠœë‹ ëª¨ë¸ DI vs ì •ë‹µ DI: {avg_scores.get('F1_TM_vs_GT_DI', 0.0):.4f}\")\n","print(f\"ì›ë³¸ ëª¨ë¸ BHC vs íŒŒì¸íŠœë‹ ëª¨ë¸ BHC: {avg_scores.get('F1_OM_vs_TM_BHC', 0.0):.4f}\")\n","print(f\"ì›ë³¸ ëª¨ë¸ DI vs íŒŒì¸íŠœë‹ ëª¨ë¸ DI: {avg_scores.get('F1_OM_vs_TM_DI', 0.0):.4f}\")\n","\n","print(\"\\n===== ê° ë¹„êµë³„ NaN (ê³„ì‚° ê±´ë„ˆëœ€) ê°œìˆ˜ =====\")\n","print(results_df.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjCNp1zXJdaC","outputId":"dde57539-a658-4ef2-8e5b-c774286d2f98","executionInfo":{"status":"ok","timestamp":1761182365052,"user_tz":-540,"elapsed":96102,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: GPU\n","ì´ 10ê°œ í–‰ì— ëŒ€í•œ BERTScore ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤ (ëª¨ë¸: roberta-large, ì¥ì¹˜: cuda:0)...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["ì´ 10ê°œ í–‰ì— ëŒ€í•œ BERTScore ê³„ì‚° ì™„ë£Œ.\n","\n","===== BERTScore F1 ê²°ê³¼ (ìƒìœ„ 5ê°œ í–‰) =====\n","   row_index  F1_OM_vs_GT_BHC  F1_TM_vs_GT_BHC  F1_OM_vs_GT_DI  \\\n","0          1         0.820352         0.854543        0.794991   \n","1          2         0.788898         0.823793        0.788979   \n","2          3         0.817770         0.829365        0.809633   \n","3          4         0.798389         0.802302        0.791982   \n","4          5         0.811931         0.850316        0.794196   \n","\n","   F1_TM_vs_GT_DI  F1_OM_vs_TM_BHC  F1_OM_vs_TM_DI  \n","0        0.832612         0.805765        0.792189  \n","1        0.834645         0.796798        0.784696  \n","2        0.887345         0.822171        0.829458  \n","3        0.844316         0.784360        0.809186  \n","4             NaN         0.805998             NaN  \n","\n","===== í‰ê·  BERTScore F1 (NaN ì œì™¸) =====\n","ì›ë³¸ ëª¨ë¸ BHC vs ì •ë‹µ BHC: 0.8086\n","íŒŒì¸íŠœë‹ ëª¨ë¸ BHC vs ì •ë‹µ BHC: 0.8415\n","ì›ë³¸ ëª¨ë¸ DI vs ì •ë‹µ DI: 0.8003\n","íŒŒì¸íŠœë‹ ëª¨ë¸ DI vs ì •ë‹µ DI: 0.8564\n","ì›ë³¸ ëª¨ë¸ BHC vs íŒŒì¸íŠœë‹ ëª¨ë¸ BHC: 0.8082\n","ì›ë³¸ ëª¨ë¸ DI vs íŒŒì¸íŠœë‹ ëª¨ë¸ DI: 0.8018\n","\n","===== ê° ë¹„êµë³„ NaN (ê³„ì‚° ê±´ë„ˆëœ€) ê°œìˆ˜ =====\n","row_index          0\n","F1_OM_vs_GT_BHC    1\n","F1_TM_vs_GT_BHC    1\n","F1_OM_vs_GT_DI     1\n","F1_TM_vs_GT_DI     1\n","F1_OM_vs_TM_BHC    1\n","F1_OM_vs_TM_DI     2\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["# 3.1 ì‹œê°í™”"],"metadata":{"id":"Wn2VkDX_EInj"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","\n","if 'results_df' not in locals():\n","    print(\"ì˜¤ë¥˜: 'results_df' ë°ì´í„°í”„ë ˆì„ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n","else:\n","    print(\"ì‹œê°í™” ì§„í–‰ ì¤‘...\")\n","    # --- ì‹œê°í™” ---\n","\n","    # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\n","    sns.set_style(\"whitegrid\")\n","\n","    # 1í–‰ 2ì—´ì˜ ê·¸ë˜í”„ ì˜ì—­ ìƒì„± (BHCìš©, DIìš©)\n","    fig, axes = plt.subplots(1, 2, figsize=(14, 7)) # ê°€ë¡œ í¬ê¸° ëŠ˜ë¦¼\n","\n","    # 1. BHC ì ìˆ˜ ë¹„êµ ìƒì ê·¸ë¦¼ (OM vs GT, TM vs GT)\n","    # BHC ë¹„êµì— ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ì„ íƒ\n","    bhc_scores_to_plot = results_df[['F1_OM_vs_GT_BHC', 'F1_TM_vs_GT_BHC']]\n","    # ê·¸ë˜í”„ ë ˆì´ë¸”ì„ ìœ„í•œ ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½\n","    bhc_scores_to_plot.columns = ['Original vs. GT', 'Fine-tuned vs. GT']\n","\n","    sns.boxplot(data=bhc_scores_to_plot, ax=axes[0], palette=\"pastel\") # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ë³€ê²½\n","    axes[0].set_title('BHC: BERTScore F1 Comparison (vs. Ground Truth)') # ì œëª© ìˆ˜ì •\n","    axes[0].set_ylabel('BERTScore F1')\n","    axes[0].set_ylim(0, 1) # F1 ì ìˆ˜ ë²”ìœ„ (0 ~ 1)\n","\n","    # 2. DI ì ìˆ˜ ë¹„êµ ìƒì ê·¸ë¦¼ (OM vs GT, TM vs GT)\n","    # DI ë¹„êµì— ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ì„ íƒ\n","    di_scores_to_plot = results_df[['F1_OM_vs_GT_DI', 'F1_TM_vs_GT_DI']]\n","    # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½\n","    di_scores_to_plot.columns = ['Original vs. GT', 'Fine-tuned vs. GT']\n","\n","    sns.boxplot(data=di_scores_to_plot, ax=axes[1], palette=\"pastel\")\n","    axes[1].set_title('DI: BERTScore F1 Comparison (vs. Ground Truth)') # ì œëª© ìˆ˜ì •\n","    axes[1].set_ylabel('BERTScore F1')\n","    axes[1].set_ylim(0, 1)\n","\n","    # ê·¸ë˜í”„ ë ˆì´ì•„ì›ƒ ì¡°ì • ë° íŒŒì¼ ì €ì¥\n","    plt.tight_layout()\n","    plt.savefig(\"bertscore_vs_gt_comparison_boxplot.png\") # íŒŒì¼ ì´ë¦„ ë³€ê²½\n","\n","    # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥\n","    print(\"ìƒì ê·¸ë¦¼ì´ bertscore_vs_gt_comparison_boxplot.png ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","    # plt.show()"],"metadata":{"id":"jBZnpUP_EOEv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. í‰ê°€ (BLEU)"],"metadata":{"id":"ZyBTiXtwDJMA"}},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"id":"c6jRlP6GEuMe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Colabì—ì„œ ì²˜ìŒ ì‹¤í–‰ ì‹œ í•„ìš”)\n","# !pip install nltk\n","\n","import pandas as pd\n","import re\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","import numpy as np # NaN ê°’ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ numpy ì„í¬íŠ¸\n","\n","# nltk ë°ì´í„° ë‹¤ìš´ë¡œë“œ (punkt í† í¬ë‚˜ì´ì €)\n","try:\n","    nltk.data.find('tokenizers/punkt')\n","except LookupError:\n","    nltk.download('punkt')\n","\n","# --- ì„¤ì • ---\n","path = \"/content/drive/MyDrive/DILAB/Qwen2-7B-Instruct/results/original_1.3/original_1_3_results.parquet\"\n","VIEW_NUM = None # Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ í–‰ ì²˜ë¦¬, ìˆ«ìë¡œ ì§€ì •í•˜ë©´ ìƒìœ„ Nê°œ í–‰ë§Œ ì²˜ë¦¬\n","\n","df = pd.read_parquet(path)\n","\n","# í…ìŠ¤íŠ¸ ë¶„ë¦¬ í•¨ìˆ˜\n","def split_bhc_di(text):\n","    if not isinstance(text, str):\n","        return \"\", \"\"\n","    bhc_pattern = r\"Brief Hospital Course\\s*\"\n","    di_pattern = r\"Discharge Instructions\\s*\"\n","    bhc_match = re.search(bhc_pattern, text, re.IGNORECASE)\n","    di_match = re.search(di_pattern, text, re.IGNORECASE)\n","    bhc_text = \"\"\n","    di_text = \"\"\n","    if bhc_match and di_match:\n","        bhc_start = bhc_match.end()\n","        bhc_end = di_match.start()\n","        bhc_text = text[bhc_start:bhc_end].strip().lstrip(':').strip()\n","        di_start = di_match.end()\n","        di_text = text[di_start:].strip().lstrip(':').strip()\n","    elif bhc_match:\n","        bhc_start = bhc_match.end()\n","        bhc_text = text[bhc_start:].strip().lstrip(':').strip()\n","    elif di_match:\n","        di_start = di_match.end()\n","        di_text = text[di_start:].strip().lstrip(':').strip()\n","    return bhc_text, di_text\n","\n","# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n","bleu_scores_list = []\n","\n","# ì²˜ë¦¬í•  í–‰ ê²°ì •\n","if VIEW_NUM is None:\n","    rows_to_process = df.iterrows()\n","    total_rows = len(df)\n","else:\n","    rows_to_process = df.head(VIEW_NUM).iterrows()\n","    total_rows = VIEW_NUM\n","\n","print(f\"ì´ {total_rows}ê°œ í–‰ì— ëŒ€í•œ BLEU-4 ì ìˆ˜ ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n","\n","# Smoothing function ì •ì˜\n","chencherry = SmoothingFunction()\n","\n","# í† í¬ë‚˜ì´ì§• ë° ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ ì •ì˜\n","def calculate_bleu(hypothesis_str, reference_str):\n","    # í•¨ìˆ˜ ë‚´ë¶€ ë¹ˆ ë¬¸ìì—´ ì²´í¬ ì œê±° (í˜¸ì¶œ ì „ì— ì²´í¬)\n","    hypothesis_tokens = hypothesis_str.split()\n","    reference_tokens_list = [reference_str.split()]\n","    try:\n","        score_val = sentence_bleu(reference_tokens_list, hypothesis_tokens, smoothing_function=chencherry.method1)\n","        return score_val\n","    except Exception as e:\n","        print(f\" - í–‰ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ (BLEU): {e}\") # ì˜¤ë¥˜ ë°œìƒ ì‹œ í–‰ ë²ˆí˜¸ ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n","        return np.nan # ì˜¤ë¥˜ ì‹œ NaN ë°˜í™˜\n","\n","# í–‰ ë°˜ë³µ, í…ìŠ¤íŠ¸ ë¶„ë¦¬, BLEU ì ìˆ˜ ê³„ì‚°\n","for idx, row in rows_to_process:\n","    if (idx + 1) % 50 == 0: # 50í–‰ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥\n","        print(f\"í–‰ {idx + 1}/{total_rows} ì²˜ë¦¬ ì¤‘...\")\n","\n","    # ëª¨ë¸ ì¶œë ¥ê°’ ê°€ì ¸ì˜¤ê¸°\n","    om_output = row['original_model_output']\n","    tm_output = row['trained_model_output']\n","\n","    # ì •ë‹µ(Ground Truth) ê°€ì ¸ì˜¤ê¸° (NaN ê°’ ì²˜ë¦¬)\n","    gt_bhc = str(row['original_bhc']) if pd.notna(row['original_bhc']) else \"\"\n","    gt_di = str(row['original_di']) if pd.notna(row['original_di']) else \"\"\n","\n","    # ëª¨ë¸ ì¶œë ¥ê°’ ë¶„ë¦¬\n","    om_bhc, om_di = split_bhc_di(om_output)\n","    tm_bhc, tm_di = split_bhc_di(tm_output)\n","\n","    # --- BLEU ì ìˆ˜ ê³„ì‚° ---\n","    bleu_om_gt_bhc, bleu_tm_gt_bhc, bleu_om_gt_di, bleu_tm_gt_di = np.nan, np.nan, np.nan, np.nan\n","\n","    # ì ìˆ˜ ê³„ì‚°\n","    if om_bhc and gt_bhc:\n","        bleu_om_gt_bhc = calculate_bleu(om_bhc, gt_bhc)\n","    if tm_bhc and gt_bhc:\n","        bleu_tm_gt_bhc = calculate_bleu(tm_bhc, gt_bhc)\n","    if om_di and gt_di:\n","        bleu_om_gt_di  = calculate_bleu(om_di, gt_di)\n","    if tm_di and gt_di:\n","        bleu_tm_gt_di  = calculate_bleu(tm_di, gt_di)\n","\n","    # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n","    bleu_scores_list.append({\n","        'row_index': idx + 1,\n","        'BLEU4_OM_vs_GT_BHC': bleu_om_gt_bhc,\n","        'BLEU4_TM_vs_GT_BHC': bleu_tm_gt_bhc,\n","        'BLEU4_OM_vs_GT_DI': bleu_om_gt_di,\n","        'BLEU4_TM_vs_GT_DI': bleu_tm_gt_di,\n","    })\n","\n","print(f\"ì´ {total_rows}ê°œ í–‰ì— ëŒ€í•œ BLEU-4 ì ìˆ˜ ê³„ì‚° ì™„ë£Œ.\")\n","\n","# ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n","bleu_results_df = pd.DataFrame(bleu_scores_list)\n","\n","# ê²°ê³¼ ì¶œë ¥ (ìƒìœ„ 5ê°œ í–‰)\n","print(\"\\n===== BLEU-4 ì ìˆ˜ ê²°ê³¼ (ìƒìœ„ 5ê°œ í–‰) =====\")\n","print(bleu_results_df.head()) # NaN ê°’ì´ í¬í•¨ëœ ì±„ë¡œ ì¶œë ¥ë  ìˆ˜ ìˆìŒ\n","\n","# í‰ê·  ì ìˆ˜ ì¶œë ¥\n","print(\"\\n===== í‰ê·  BLEU-4 ì ìˆ˜ (NaN ì œì™¸) =====\")\n","avg_bleu_scores = bleu_results_df.mean(numeric_only=True) # skipna=Trueê°€ ê¸°ë³¸ê°’\n","print(f\"ì›ë³¸ ëª¨ë¸ BHC vs ì •ë‹µ BHC: {avg_bleu_scores.get('BLEU4_OM_vs_GT_BHC', 0.0):.4f}\")\n","print(f\"íŒŒì¸íŠœë‹ ëª¨ë¸ BHC vs ì •ë‹µ BHC: {avg_bleu_scores.get('BLEU4_TM_vs_GT_BHC', 0.0):.4f}\")\n","print(f\"ì›ë³¸ ëª¨ë¸ DI vs ì •ë‹µ DI: {avg_bleu_scores.get('BLEU4_OM_vs_GT_DI', 0.0):.4f}\")\n","print(f\"íŒŒì¸íŠœë‹ ëª¨ë¸ DI vs ì •ë‹µ DI: {avg_bleu_scores.get('BLEU4_TM_vs_GT_DI', 0.0):.4f}\")\n","\n","print(\"\\n===== ê° ë¹„êµë³„ NaN (ê³„ì‚° ê±´ë„ˆëœ€) ê°œìˆ˜ =====\")\n","print(bleu_results_df.isnull().sum())\n"],"metadata":{"id":"sSFRlg75c5MZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761182207088,"user_tz":-540,"elapsed":193,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"e73bb5b5-f181-40fc-d6fd-853ebed3456a"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["ì´ 10ê°œ í–‰ì— ëŒ€í•œ BLEU-4 ì ìˆ˜ ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n","ì´ 10ê°œ í–‰ì— ëŒ€í•œ BLEU-4 ì ìˆ˜ ê³„ì‚° ì™„ë£Œ.\n","\n","===== BLEU-4 ì ìˆ˜ ê²°ê³¼ (ìƒìœ„ 5ê°œ í–‰) =====\n","   row_index  BLEU4_OM_vs_GT_BHC  BLEU4_TM_vs_GT_BHC  BLEU4_OM_vs_GT_DI  \\\n","0          1            0.009228            0.177181           0.004766   \n","1          2            0.003957            0.008319           0.002432   \n","2          3            0.004316            0.174411           0.003733   \n","3          4            0.001810            0.063336           0.005457   \n","4          5            0.000999            0.001277           0.001544   \n","\n","   BLEU4_TM_vs_GT_DI  \n","0           0.001604  \n","1           0.013378  \n","2           0.141416  \n","3           0.005420  \n","4                NaN  \n","\n","===== í‰ê·  BLEU-4 ì ìˆ˜ (NaN ì œì™¸) =====\n","ì›ë³¸ ëª¨ë¸ BHC vs ì •ë‹µ BHC: 0.0042\n","íŒŒì¸íŠœë‹ ëª¨ë¸ BHC vs ì •ë‹µ BHC: 0.0795\n","ì›ë³¸ ëª¨ë¸ DI vs ì •ë‹µ DI: 0.0066\n","íŒŒì¸íŠœë‹ ëª¨ë¸ DI vs ì •ë‹µ DI: 0.0413\n","\n","===== ê° ë¹„êµë³„ NaN (ê³„ì‚° ê±´ë„ˆëœ€) ê°œìˆ˜ =====\n","row_index             0\n","BLEU4_OM_vs_GT_BHC    1\n","BLEU4_TM_vs_GT_BHC    1\n","BLEU4_OM_vs_GT_DI     1\n","BLEU4_TM_vs_GT_DI     1\n","dtype: int64\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","\n","if 'bleu_results_df' not in locals():\n","    print(\"ì˜¤ë¥˜: 'bleu_results_df' ë°ì´í„°í”„ë ˆì„ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n","else:\n","    print(\"BLEU-4 ì ìˆ˜ ì‹œê°í™” ì§„í–‰ ì¤‘...\")\n","    # --- ì‹œê°í™” ---\n","\n","    # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\n","    sns.set_style(\"whitegrid\")\n","\n","    # 1í–‰ 2ì—´ì˜ ê·¸ë˜í”„ ì˜ì—­ ìƒì„± (BHCìš©, DIìš©)\n","    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n","\n","    # 1. BHC ì ìˆ˜ ë¹„êµ ìƒì ê·¸ë¦¼ (OM vs GT, TM vs GT)\n","    # BHC ë¹„êµì— ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ì„ íƒ\n","    bhc_bleu_scores_to_plot = bleu_results_df[['BLEU4_OM_vs_GT_BHC', 'BLEU4_TM_vs_GT_BHC']]\n","    # ê·¸ë˜í”„ ë ˆì´ë¸”ì„ ìœ„í•œ ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½\n","    bhc_bleu_scores_to_plot.columns = ['Original vs. GT', 'Fine-tuned vs. GT']\n","\n","    sns.boxplot(data=bhc_bleu_scores_to_plot, ax=axes[0], palette=\"pastel\")\n","    axes[0].set_title('BHC: BLEU-4 Score Comparison (vs. Ground Truth)')\n","    axes[0].set_ylabel('BLEU-4 Score')\n","    # BLEU ì ìˆ˜ëŠ” ë³´í†µ ë‚®ìœ¼ë¯€ë¡œ, ìƒí•œì„ ì„ 1.0 ëŒ€ì‹  ë°ì´í„° ìµœëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ ìë™ ì¡°ì ˆí•˜ê±°ë‚˜\n","    # ë°ì´í„° ë¶„í¬ë¥¼ ë³´ê³  ì ì ˆíˆ ì„¤ì • (ì˜ˆ: 0.2 ë˜ëŠ” 0.3)\n","    axes[0].set_ylim(0, 1)\n","\n","    # 2. DI ì ìˆ˜ ë¹„êµ ìƒì ê·¸ë¦¼ (OM vs GT, TM vs GT)\n","    # DI ë¹„êµì— ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ì„ íƒ\n","    di_bleu_scores_to_plot = bleu_results_df[['BLEU4_OM_vs_GT_DI', 'BLEU4_TM_vs_GT_DI']]\n","    # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½\n","    di_bleu_scores_to_plot.columns = ['Original vs. GT', 'Fine-tuned vs. GT']\n","\n","    sns.boxplot(data=di_bleu_scores_to_plot, ax=axes[1], palette=\"pastel\")\n","    axes[1].set_title('DI: BLEU-4 Score Comparison (vs. Ground Truth)')\n","    axes[1].set_ylabel('BLEU-4 Score')\n","    axes[1].set_ylim(0, 1) # yì¶• ë²”ìœ„ ì„¤ì •\n","\n","    # ê·¸ë˜í”„ ë ˆì´ì•„ì›ƒ ì¡°ì • ë° íŒŒì¼ ì €ì¥\n","    plt.tight_layout()\n","    plt.savefig(\"bleu4_comparison_boxplot.png\") # íŒŒì¼ ì´ë¦„ ì§€ì •\n","\n","    # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥\n","    print(\"ìƒì ê·¸ë¦¼ì´ bleu4_comparison_boxplot.png ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","    plt.show()"],"metadata":{"id":"LpGGkFfNFQPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WtHlPvmFFQdk"},"execution_count":null,"outputs":[]}]}