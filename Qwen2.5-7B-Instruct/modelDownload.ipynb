{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNR0JhYqd6zUdKSzvxi20lN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mOvMwrcK5nz5"},"outputs":[],"source":["!pip install transformers torch accelerate bitsandbytes"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","print(\"구글 드라이브 연결 완료|\")"],"metadata":{"id":"eijlh_ScMjXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# 다운로드할 모델 이름\n","model_name = \"Qwen/Qwen2-7B-Instruct\"\n","\n","print(f\"'{model_name}' 모델 다운로드를 시작합니다\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    torch_dtype=\"auto\",\n","    device_map=\"auto\"\n",")\n","\n","print(\"모델 로딩 완료\")\n","\n","# 모델을 저장할 드라이브 경로를 지정\n","save_directory = \"/content/drive/MyDrive/DILAB/Qwen2-7B-Instruct\"\n","\n","model.save_pretrained(save_directory)\n","tokenizer.save_pretrained(save_directory)\n","\n","print(f\"모델이 저장되었습니다.\")"],"metadata":{"id":"kceKoyZH9Z8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ulWMQ4_s0zbr"},"execution_count":null,"outputs":[]}]}